#!/usr/bin/env python3
"""
OpenTrade å¤‡ä»½æ¢å¤è„šæœ¬

åŠŸèƒ½ï¼š
1. å¤‡ä»½é…ç½®æ–‡ä»¶
2. å¤‡ä»½æ•°æ®åº“
3. å¤‡ä»½ç­–ç•¥æ•°æ®
4. ä¸€é”®æ¢å¤

Usage:
    python backup.py backup           # æ‰§è¡Œå¤‡ä»½
    python backup.py restore latest   # æ¢å¤æœ€æ–°å¤‡ä»½
    python backup.py list             # åˆ—å‡ºå¤‡ä»½
    python backup.py clean 7          # æ¸…ç†7å¤©å‰çš„å¤‡ä»½
"""

import argparse
import gzip
import json
import os
import shutil
import sqlite3
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

import yaml

# é…ç½®
BACKUP_DIR = Path("/root/.opentrade/backups")
RETENTION_DAYS = 7
COMPRESSION_LEVEL = 9


def ensure_backup_dir():
    """ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨"""
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    return BACKUP_DIR


def get_timestamp() -> str:
    """è·å–æ—¶é—´æˆ³"""
    return datetime.utcnow().strftime("%Y%m%d_%H%M%S")


def backup_config() -> Path:
    """å¤‡ä»½é…ç½®æ–‡ä»¶"""
    config_src = Path.home() / ".opentrade" / "config.yaml"
    if not config_src.exists():
        print("[yellow]âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡[/yellow]")
        return None
    
    backup_dir = ensure_backup_dir()
    backup_file = backup_dir / f"config_{get_timestamp()}.yaml.gz"
    
    with open(config_src, 'rb') as f_in:
        with gzip.open(backup_file, 'wb', compresslevel=COMPRESSION_LEVEL) as f_out:
            shutil.copyfileobj(f_in, f_out)
    
    print(f"âœ… é…ç½®å·²å¤‡ä»½: {backup_file.name}")
    return backup_file


def backup_strategies() -> Path:
    """å¤‡ä»½ç­–ç•¥æ•°æ®"""
    data_dir = Path("/root/.opentrade/data")
    if not data_dir.exists():
        print("[yellow]âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡[/yellow]")
        return None
    
    backup_dir = ensure_backup_dir()
    backup_file = backup_dir / f"strategies_{get_timestamp()}.json.gz"
    
    # æ”¶é›†æ‰€æœ‰ç­–ç•¥æ–‡ä»¶
    strategy_files = list(data_dir.glob("*.json"))
    if not strategy_files:
        print("[yellow]âš ï¸ æ²¡æœ‰ç­–ç•¥æ–‡ä»¶ï¼Œè·³è¿‡[/yellow]")
        return None
    
    all_data = {
        "timestamp": datetime.utcnow().isoformat(),
        "files": {},
    }
    
    for file in strategy_files:
        try:
            with open(file, 'r') as f:
                all_data["files"][file.name] = json.load(f)
        except Exception as e:
            print(f"[yellow]âš ï¸ è¯»å– {file.name} å¤±è´¥: {e}[/yellow]")
    
    with gzip.open(backup_file, 'wt', compresslevel=COMPRESSION_LEVEL) as f:
        json.dump(all_data, f, indent=2, default=str)
    
    print(f"âœ… ç­–ç•¥å·²å¤‡ä»½: {backup_file.name}")
    return backup_file


def backup_evolution_history() -> Path:
    """å¤‡ä»½è¿›åŒ–å†å²"""
    history_file = Path("/root/opentrade/data/evolution_history.json")
    if not history_file.exists():
        # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„ä½ç½®
        alt_file = Path("/root/.opentrade/data/evolution_history.json")
        if not alt_file.exists():
            print("[yellow]âš ï¸ è¿›åŒ–å†å²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡[/yellow]")
            return None
        history_file = alt_file
    
    backup_dir = ensure_backup_dir()
    backup_file = backup_dir / f"evolution_{get_timestamp()}.json.gz"
    
    with open(history_file, 'rb') as f_in:
        with gzip.open(backup_file, 'wb', compresslevel=COMPRESSION_LEVEL) as f_out:
            shutil.copyfileobj(f_in, f_out)
    
    print(f"âœ… è¿›åŒ–å†å²å·²å¤‡ä»½: {backup_file.name}")
    return backup_file


def backup_docker_data() -> Optional[Path]:
    """å¤‡ä»½ Docker volumes æ•°æ®"""
    docker_dir = BACKUP_DIR / "docker"
    docker_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # å¤‡ä»½ PostgreSQL æ•°æ®
        result = subprocess.run(
            ["docker", "cp", "opentrade-postgres-1:/var/lib/postgresql", str(docker_dir)],
            capture_output=True,
            timeout=60
        )
        if result.returncode == 0:
            print("âœ… PostgreSQL æ•°æ®å·²å¤‡ä»½")
        
        # å¤‡ä»½ Redis æ•°æ®
        result = subprocess.run(
            ["docker", "cp", "opentrade-redis-1:/data", str(docker_dir / "redis")],
            capture_output=True,
            timeout=30
        )
        if result.returncode == 0:
            print("âœ… Redis æ•°æ®å·²å¤‡ä»½")
        
        # åˆ›å»º tar.gz å½’æ¡£
        tar_file = BACKUP_DIR / f"docker_{get_timestamp()}.tar.gz"
        subprocess.run(
            ["tar", "-czf", str(tar_file), "-C", str(BACKUP_DIR), "docker"],
            check=True
        )
        shutil.rmtree(docker_dir)
        
        print(f"âœ… Docker æ•°æ®å·²å¤‡ä»½: {tar_file.name}")
        return tar_file
        
    except subprocess.TimeoutExpired:
        print("[red]âŒ Docker å¤‡ä»½è¶…æ—¶[/red]")
        return None
    except Exception as e:
        print(f"[yellow]âš ï¸ Docker å¤‡ä»½å¤±è´¥: {e}[/yellow]")
        return None


def backup_all() -> list[Path]:
    """æ‰§è¡Œå®Œæ•´å¤‡ä»½"""
    print("\n[bold cyan]ğŸ”’ OpenTrade å¤‡ä»½å¼€å§‹[/bold cyan]")
    print("=" * 50)
    
    backups = []
    
    # å¤‡ä»½é…ç½®
    config_backup = backup_config()
    if config_backup:
        backups.append(config_backup)
    
    # å¤‡ä»½ç­–ç•¥
    strategy_backup = backup_strategies()
    if strategy_backup:
        backups.append(strategy_backup)
    
    # å¤‡ä»½è¿›åŒ–å†å²
    evolution_backup = backup_evolution_history()
    if evolution_backup:
        backups.append(evolution_backup)
    
    # ç»Ÿè®¡
    total_size = sum(f.stat().st_size for f in backups) if backups else 0
    print(f"\nğŸ“¦ å¤‡ä»½å®Œæˆ: {len(backups)} ä¸ªæ–‡ä»¶, {total_size / 1024:.1f} KB")
    
    # æ¸…ç†æ—§å¤‡ä»½
    clean_old_backups()
    
    return backups


def list_backups():
    """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
    backup_dir = ensure_backup_dir()
    backups = sorted(backup_dir.glob("*.gz"), reverse=True)
    
    if not backups:
        print("\n[yellow]âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½æ–‡ä»¶[/yellow]")
        return []
    
    print(f"\n[bold]ğŸ“‹ å¯ç”¨å¤‡ä»½ ({len(backups)} ä¸ª)[/bold]")
    print("-" * 60)
    
    for backup in backups[:10]:  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
        size = backup.stat().st_size
        mtime = datetime.fromtimestamp(backup.stat().st_mtime)
        age = datetime.utcnow() - mtime
        
        age_str = f"{age.seconds // 3600}h ago" if age.days == 0 else f"{age.days}d ago"
        
        print(f"  {backup.name:40s} {size/1024:8.1f} KB  {age_str}")
    
    return backups


def clean_old_backups(days: int = None):
    """æ¸…ç†æ—§å¤‡ä»½"""
    if days is None:
        days = RETENTION_DAYS
    
    backup_dir = ensure_backup_dir()
    cutoff = datetime.utcnow() - timedelta(days=days)
    
    removed = 0
    for backup in backup_dir.glob("*.gz"):
        mtime = datetime.fromtimestamp(backup.stat().st_mtime)
        if mtime < cutoff:
            backup.unlink()
            removed += 1
    
    if removed > 0:
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆ: åˆ é™¤äº† {removed} ä¸ªæ—§å¤‡ä»½")


def restore_backup(backup_name: str) -> bool:
    """æ¢å¤å¤‡ä»½"""
    backup_dir = ensure_backup_dir()
    
    # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶
    if backup_name == "latest":
        backups = sorted(backup_dir.glob("*.gz"), reverse=True)
        if not backups:
            print("[red]âŒ æ²¡æœ‰å¯ç”¨çš„å¤‡ä»½[/red]")
            return False
        backup_file = backups[0]
    else:
        backup_file = backup_dir / backup_name
        if not backup_file.exists():
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            matches = list(backup_dir.glob(f"*{backup_name}*"))
            if matches:
                backup_file = matches[0]
            else:
                print(f"[red]âŒ æ‰¾ä¸åˆ°å¤‡ä»½: {backup_name}[/red]")
                return False
    
    print(f"\n[bold cyan]ğŸ”“ æ¢å¤å¤‡ä»½: {backup_file.name}[/bold cyan]")
    
    # ç¡®å®šå¤‡ä»½ç±»å‹
    if "config" in backup_file.name:
        return restore_config(backup_file)
    elif "strategy" in backup_file.name:
        return restore_strategies(backup_file)
    elif "evolution" in backup_file.name:
        return restore_evolution(backup_file)
    else:
        print("[red]âŒ æœªçŸ¥å¤‡ä»½ç±»å‹[/red]")
        return False


def restore_config(backup_file: Path) -> bool:
    """æ¢å¤é…ç½®"""
    config_dst = Path.home() / ".opentrade" / "config.yaml"
    
    try:
        with gzip.open(backup_file, 'rb') as f:
            content = f.read()
        
        # å¤‡ä»½å½“å‰é…ç½®
        if config_dst.exists():
            backup_current = config_dst.with_suffix(f".backup_{get_timestamp()}")
            shutil.copy(config_dst, backup_current)
            print(f"ğŸ“ å½“å‰é…ç½®å·²å¤‡ä»½: {backup_current.name}")
        
        with open(config_dst, 'wb') as f:
            f.write(content)
        
        print(f"âœ… é…ç½®å·²æ¢å¤: {config_dst}")
        return True
        
    except Exception as e:
        print(f"[red]âŒ æ¢å¤é…ç½®å¤±è´¥: {e}[/red]")
        return False


def restore_strategies(backup_file: Path) -> bool:
    """æ¢å¤ç­–ç•¥"""
    data_dir = Path("/root/.opentrade/data")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        with gzip.open(backup_file, 'rt') as f:
            data = json.load(f)
        
        for filename, content in data.get("files", {}).items():
            file_path = data_dir / filename
            
            # å¤‡ä»½å½“å‰æ–‡ä»¶
            if file_path.exists():
                backup = file_path.with_suffix(f".backup_{get_timestamp()}")
                shutil.copy(file_path, backup)
            
            with open(file_path, 'w') as f:
                json.dump(content, f, indent=2)
            
            print(f"âœ… ç­–ç•¥å·²æ¢å¤: {filename}")
        
        return True
        
    except Exception as e:
        print(f"[red]âŒ æ¢å¤ç­–ç•¥å¤±è´¥: {e}[/red]")
        return False


def restore_evolution(backup_file: Path) -> bool:
    """æ¢å¤è¿›åŒ–å†å²"""
    history_file = Path("/root/opentrade/data/evolution_history.json")
    
    try:
        with gzip.open(backup_file, 'rb') as f_in:
            content = f_in.read()
        
        # å¤‡ä»½å½“å‰
        if history_file.exists():
            backup = history_file.with_suffix(f".backup_{get_timestamp()}")
            shutil.copy(history_file, backup)
        
        with open(history_file, 'wb') as f:
            f.write(content)
        
        print(f"âœ… è¿›åŒ–å†å²å·²æ¢å¤: {history_file}")
        return True
        
    except Exception as e:
        print(f"[red]âŒ æ¢å¤è¿›åŒ–å†å²å¤±è´¥: {e}[/red]")
        return False


def main():
    parser = argparse.ArgumentParser(description="OpenTrade å¤‡ä»½æ¢å¤å·¥å…·")
    subparsers = parser.add_subparsers(dest="command", help="å­å‘½ä»¤")
    
    # backup
    parser_backup = subparsers.add_parser("backup", help="æ‰§è¡Œå¤‡ä»½")
    parser_backup.add_argument("--full", action="store_true", help="åŒ…å« Docker æ•°æ®")
    
    # restore
    parser_restore = subparsers.add_parser("restore", help="æ¢å¤å¤‡ä»½")
    parser_restore.add_argument("backup", help="å¤‡ä»½æ–‡ä»¶åæˆ– 'latest'")
    
    # list
    subparsers.add_parser("list", help="åˆ—å‡ºå¤‡ä»½")
    
    # clean
    parser_clean = subparsers.add_parser("clean", help="æ¸…ç†æ—§å¤‡ä»½")
    parser_clean.add_argument("days", type=int, nargs="?", default=7, help="ä¿ç•™å¤©æ•°")
    
    args = parser.parse_args()
    
    if args.command == "backup":
        backup_all()
        
    elif args.command == "restore":
        restore_backup(args.backup)
        
    elif args.command == "list":
        list_backups()
        
    elif args.command == "clean":
        clean_old_backups(args.days)
        
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
